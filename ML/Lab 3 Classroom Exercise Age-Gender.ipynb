{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3e16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45665637",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Input image \u001b[39;00m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmario\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmario.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m----> 3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m720\u001b[39m, \u001b[38;5;241m640\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# Input image \n",
    "image = cv2.imread(r\"C:\\Users\\mario\\Downloads\\mario.jpeg\") \n",
    "image = cv2.resize(image, (720, 640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5bbdbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Models and set mean values \n",
    "face1 = \"opencv_face_detector.pbtxt\"\n",
    "face2 = \"opencv_face_detector_uint8.pb\"\n",
    "age1 = \"age_deploy.prototxt\"\n",
    "age2 = \"age_net.caffemodel\"\n",
    "gen1 = \"gender_deploy.prototxt\"\n",
    "gen2 = \"gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746) \n",
    "\n",
    "# Using models \n",
    "# Face \n",
    "face = cv2.dnn.readNet(face2, face1) \n",
    "\n",
    "# age \n",
    "age = cv2.dnn.readNet(age2, age1) \n",
    "\n",
    "# gender \n",
    "gen = cv2.dnn.readNet(gen2, gen1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9459f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories of distribution \n",
    "la = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', \n",
    "\t'(25-32)', '(38-43)', '(48-53)', '(60-100)'] \n",
    "lg = ['Male', 'Female'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72461fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copy image \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fr_cv \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Copy image \n",
    "fr_cv = image.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4a26798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fr_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Face detection \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fr_h \u001b[38;5;241m=\u001b[39m fr_cv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m      3\u001b[0m fr_w \u001b[38;5;241m=\u001b[39m fr_cv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m      4\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(fr_cv, \u001b[38;5;241m1.0\u001b[39m, (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m), \n\u001b[0;32m      5\u001b[0m \t\t\t\t\t\t\t[\u001b[38;5;241m104\u001b[39m, \u001b[38;5;241m117\u001b[39m, \u001b[38;5;241m123\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'fr_cv' is not defined"
     ]
    }
   ],
   "source": [
    "# Face detection \n",
    "fr_h = fr_cv.shape[0] \n",
    "fr_w = fr_cv.shape[1] \n",
    "blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300), \n",
    "\t\t\t\t\t\t\t[104, 117, 123], True, False) \n",
    "\n",
    "face.setInput(blob) \n",
    "detections = face.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06e4460b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Face bounding box creation \u001b[39;00m\n\u001b[0;32m      2\u001b[0m faceBoxes \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(detections\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]): \n\u001b[0;32m      4\u001b[0m \t\n\u001b[0;32m      5\u001b[0m \t\u001b[38;5;66;03m#Bounding box creation if confidence > 0.7 \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \tconfidence \u001b[38;5;241m=\u001b[39m detections[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, i, \u001b[38;5;241m2\u001b[39m] \n\u001b[0;32m      7\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.7\u001b[39m: \n",
      "\u001b[1;31mNameError\u001b[0m: name 'detections' is not defined"
     ]
    }
   ],
   "source": [
    "# Face bounding box creation \n",
    "faceBoxes = [] \n",
    "for i in range(detections.shape[2]): \n",
    "\t\n",
    "\t#Bounding box creation if confidence > 0.7 \n",
    "\tconfidence = detections[0, 0, i, 2] \n",
    "\tif confidence > 0.7: \n",
    "\t\t\n",
    "\t\tx1 = int(detections[0, 0, i, 3]*fr_w) \n",
    "\t\ty1 = int(detections[0, 0, i, 4]*fr_h) \n",
    "\t\tx2 = int(detections[0, 0, i, 5]*fr_w) \n",
    "\t\ty2 = int(detections[0, 0, i, 6]*fr_h) \n",
    "\t\t\n",
    "\t\tfaceBoxes.append([x1, y1, x2, y2]) \n",
    "\t\t\n",
    "\t\tcv2.rectangle(fr_cv, (x1, y1), (x2, y2), \n",
    "\t\t\t\t\t(0, 255, 0), int(round(fr_h/150)), 8) \n",
    "\t\t\n",
    "faceBoxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f81424cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "# Checking if face detected or not \n",
    "if not faceBoxes: \n",
    "\tprint(\"No face detected\") \n",
    "\n",
    "# Final results (otherwise) \n",
    "# Loop for all the faces detected \n",
    "for faceBox in faceBoxes: \n",
    "\t\n",
    "\t#Extracting face as per the faceBox \n",
    "\tface = fr_cv[max(0, faceBox[1]-15): \n",
    "\t\t\t\tmin(faceBox[3]+15, fr_cv.shape[0]-1), \n",
    "\t\t\t\tmax(0, faceBox[0]-15):min(faceBox[2]+15, \n",
    "\t\t\t\t\t\t\tfr_cv.shape[1]-1)] \n",
    "\t\n",
    "\t#Extracting the main blob part \n",
    "\tblob = cv2.dnn.blobFromImage( \n",
    "\t\tface, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False) \n",
    "\t\n",
    "\t#Prediction of gender \n",
    "\tgen.setInput(blob) \n",
    "\tgenderPreds = gen.forward() \n",
    "\tgender = lg[genderPreds[0].argmax()] \n",
    "\t\n",
    "\t#Prediction of age \n",
    "\tage.setInput(blob) \n",
    "\tagePreds = age.forward() \n",
    "\tage = la[agePreds[0].argmax()] \n",
    "\t\n",
    "\t#Putting text of age and gender \n",
    "\t#At the top of box \n",
    "\tcv2.putText(fr_cv, \n",
    "\t\t\t\tf'{gender}, {age}', \n",
    "\t\t\t\t(faceBox[0]-150, faceBox[1]+10), \n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, \n",
    "\t\t\t\t1.3, \n",
    "\t\t\t\t(217, 0, 0), \n",
    "\t\t\t\t4, \n",
    "\t\t\t\tcv2.LINE_AA) \n",
    "\n",
    "\tplt.figure(figsize=(7, 7)) \n",
    "\tplt.imshow(fr_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ba8be-1bf2-4dfa-8bad-63ba247e9dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
